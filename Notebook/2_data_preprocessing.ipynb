{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9b41bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              üéØ DATA PREPROCESSING PIPELINE üéØ               \n",
      "üìÇ Loading cleaned data...\n",
      "‚úÖ Data loaded! Shape: (148442, 11)\n",
      "\n",
      "==================================================\n",
      "üîç PREPARING FEATURES\n",
      "==================================================\n",
      "‚úÖ Categorical features: ['city', 'cuisine']\n",
      "‚úÖ Numerical features: ['rating', 'rating_count', 'cost']\n",
      "\n",
      "==================================================\n",
      "üîÑ ONE-HOT ENCODING\n",
      "==================================================\n",
      "‚úÖ Encoded columns created: 2953\n",
      "\n",
      "==================================================\n",
      "üìä NORMALIZING NUMERICAL FEATURES\n",
      "==================================================\n",
      "‚úÖ Normalized features: ['rating', 'rating_count', 'cost']\n",
      "\n",
      "==================================================\n",
      "üîó COMBINING FEATURES\n",
      "==================================================\n",
      "‚úÖ Final dataset shape: (148442, 2956)\n",
      "\n",
      "==================================================\n",
      "üíæ SAVING ENCODER & SCALER\n",
      "==================================================\n",
      "‚úÖ Saved preprocessing objects to: D:\\Py_start\\Python\\project_SN\\Project4\\models\\preprocessing.pkl\n",
      "\n",
      "==================================================\n",
      "üíæ SAVING ENCODED DATA\n",
      "==================================================\n",
      "‚úÖ Encoded data saved at: D:\\Py_start\\Python\\project_SN\\Project4\\1\\swiggy_encoded_data.csv\n",
      "üìê Shape: (148442, 2956)\n",
      "\n",
      "==================================================\n",
      "üîç VERIFYING ROW COUNTS\n",
      "==================================================\n",
      "‚úÖ Row count matched: 148442\n",
      "\n",
      "==================================================\n",
      "üéâ PREPROCESSING COMPLETED SUCCESSFULLY üéâ\n",
      "==================================================\n",
      "\n",
      "üìä SUMMARY\n",
      "---------\n",
      "Total Restaurants : 148442\n",
      "Final Features    : 2956\n",
      "Categorical Used  : ['city', 'cuisine']\n",
      "Numerical Used    : ['rating', 'rating_count', 'cost']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING PIPELINE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def load_cleaned_data(file_path):\n",
    "    \"\"\"Load the cleaned data\"\"\"\n",
    "    print(\"üìÇ Loading cleaned data...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"‚úÖ Data loaded! Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Separate features for encoding\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üîç PREPARING FEATURES\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    categorical_features = ['city', 'cuisine']\n",
    "    numerical_features = ['rating', 'rating_count', 'cost']\n",
    "\n",
    "    # Validate features\n",
    "    categorical_features = [c for c in categorical_features if c in df.columns]\n",
    "    numerical_features = [n for n in numerical_features if n in df.columns]\n",
    "\n",
    "    print(f\"‚úÖ Categorical features: {categorical_features}\")\n",
    "    print(f\"‚úÖ Numerical features: {numerical_features}\")\n",
    "\n",
    "    return categorical_features, numerical_features\n",
    "\n",
    "\n",
    "def encode_categorical_features(df, categorical_features):\n",
    "    \"\"\"Apply One-Hot Encoding\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üîÑ ONE-HOT ENCODING\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Fill missing categorical values\n",
    "    df[categorical_features] = df[categorical_features].fillna(\"Unknown\")\n",
    "\n",
    "    encoder = OneHotEncoder(\n",
    "        sparse_output=False,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )\n",
    "\n",
    "    encoded_array = encoder.fit_transform(df[categorical_features])\n",
    "    feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array,\n",
    "        columns=feature_names,\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Encoded columns created: {encoded_df.shape[1]}\")\n",
    "    return encoded_df, encoder\n",
    "\n",
    "\n",
    "def normalize_numerical_features(df, numerical_features):\n",
    "    \"\"\"Normalize numerical features\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üìä NORMALIZING NUMERICAL FEATURES\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_array = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "    scaled_df = pd.DataFrame(\n",
    "        scaled_array,\n",
    "        columns=[f\"{col}_scaled\" for col in numerical_features],\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Normalized features: {numerical_features}\")\n",
    "    return scaled_df, scaler\n",
    "\n",
    "\n",
    "def combine_features(encoded_df, scaled_df):\n",
    "    \"\"\"Combine all features\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üîó COMBINING FEATURES\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    final_df = pd.concat([encoded_df, scaled_df], axis=1)\n",
    "\n",
    "    print(f\"‚úÖ Final dataset shape: {final_df.shape}\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def save_encoder(encoder, scaler, output_path):\n",
    "    \"\"\"Save encoder and scaler\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üíæ SAVING ENCODER & SCALER\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(\n",
    "            {\"encoder\": encoder, \"scaler\": scaler},\n",
    "            f\n",
    "        )\n",
    "\n",
    "    print(f\"‚úÖ Saved preprocessing objects to: {output_path}\")\n",
    "\n",
    "\n",
    "def save_encoded_data(df, output_path):\n",
    "    \"\"\"Save encoded dataset\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üíæ SAVING ENCODED DATA\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Encoded data saved at: {output_path}\")\n",
    "    print(f\"üìê Shape: {df.shape}\")\n",
    "\n",
    "\n",
    "def verify_rows(cleaned_path, encoded_path):\n",
    "    \"\"\"Verify row count consistency\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üîç VERIFYING ROW COUNTS\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    c = pd.read_csv(cleaned_path)\n",
    "    e = pd.read_csv(encoded_path)\n",
    "\n",
    "    if len(c) == len(e):\n",
    "        print(f\"‚úÖ Row count matched: {len(c)}\")\n",
    "    else:\n",
    "        print(\"‚ùå Row mismatch!\")\n",
    "        print(f\"Cleaned: {len(c)}, Encoded: {len(e)}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"üéØ DATA PREPROCESSING PIPELINE üéØ\".center(60))\n",
    "\n",
    "    # ‚úÖ UPDATED PATHS (MATCH YOUR PROJECT)\n",
    "    cleaned_file = r\"D:\\Py_start\\Python\\project_SN\\Project4\\1\\swiggy_cleaned_data.csv\"\n",
    "    encoded_file = r\"D:\\Py_start\\Python\\project_SN\\Project4\\1\\swiggy_encoded_data.csv\"\n",
    "    encoder_file = r\"D:\\Py_start\\Python\\project_SN\\Project4\\models\\preprocessing.pkl\"\n",
    "\n",
    "    try:\n",
    "        df = load_cleaned_data(cleaned_file)\n",
    "\n",
    "        categorical_features, numerical_features = prepare_features(df)\n",
    "\n",
    "        encoded_df, encoder = encode_categorical_features(df, categorical_features)\n",
    "        scaled_df, scaler = normalize_numerical_features(df, numerical_features)\n",
    "\n",
    "        final_df = combine_features(encoded_df, scaled_df)\n",
    "\n",
    "        save_encoder(encoder, scaler, encoder_file)\n",
    "        save_encoded_data(final_df, encoded_file)\n",
    "\n",
    "        verify_rows(cleaned_file, encoded_file)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"üéâ PREPROCESSING COMPLETED SUCCESSFULLY üéâ\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        print(f\"\"\"\n",
    "üìä SUMMARY\n",
    "---------\n",
    "Total Restaurants : {final_df.shape[0]}\n",
    "Final Features    : {final_df.shape[1]}\n",
    "Categorical Used  : {categorical_features}\n",
    "Numerical Used    : {numerical_features}\n",
    "\"\"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå PREPROCESSING FAILED\")\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
